# Fleet Size Planning in Crowdsourced Delivery: Balancing Service Level and Driver Utilization

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Gurobi](https://img.shields.io/badge/Gurobi-Optimization-red.svg)](https://www.gurobi.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Research Implementation**: Code for the paper *"Fleet Size Planning in Crowdsourced Delivery: Balancing Service Level and Driver Utilization"*

---

## The Research Problem

Crowdsourced delivery platforms (e.g., DoorDash, Instacart, Uber Eats) face a fundamental **trade-off**: they need to maintain enough drivers to fulfill customer orders quickly (high **service level**), but having too many drivers means each driver gets fewer deliveries and lower earnings (poor **driver utilization**).

This project develops optimization algorithms to solve the **fleet size planning problem**:

> **How many drivers should the platform activate in each planning period to maximize demand fulfillment while ensuring drivers earn enough to meet minimum wage guarantees?**

### Why This Matters

| Stakeholder | Concern | Our Solution |
|------------|---------|--------------|
| **Platform** | Fulfill as many orders as possible | Optimize pool sizes to match predicted demand |
| **Customers** | Fast, reliable deliveries | Maintain adequate driver supply for service level |
| **Drivers** | Earn minimum wage guarantee | Utilization-aware matching ensures drivers meet thresholds |

---

## Key Concepts

### Pool Size Decision
At the start of each planning period (e.g., hourly), the platform decides how many drivers to "activate" from a pool of available gig workers. Too few â†’ unmet demand. Too many â†’ underutilized drivers.

### Wage Guarantee Constraint
Many platforms offer drivers a minimum earnings guarantee (e.g., $15/hour). A driver "meets the guarantee" if their **utilization rate** (time spent delivering / total active time) exceeds a threshold W (typically 80%).

### The Trade-off
- **Larger pool size** â†’ Higher demand fulfillment, but lower driver utilization
- **Smaller pool size** â†’ Higher driver utilization, but more unfulfilled orders

Our algorithms find the **optimal balance** through mathematical optimization.

---

## Project Structure: Three Approaches

This repository contains **three distinct implementations**, each solving the fleet size planning problem with different techniques:

```
Fleet-Size-Planning-in-Crowdsourced-Delivery/
â”‚
â”œâ”€â”€ ğŸ“ Deterministic_Matching/          [APPROACH 1: Single-Period Optimization]
â”‚   â”‚
â”‚   â”‚   Core driver-order matching models that solve the assignment problem
â”‚   â”‚   for a SINGLE time period with KNOWN demand (deterministic setting).
â”‚   â”‚
â”‚   â”œâ”€â”€ Deterministic_Setting_Gurobi_Model_With_Fixed_Profit.py
â”‚   â”‚       â†’ Basic bipartite matching: assigns drivers to orders to maximize profit
â”‚   â”‚       â†’ Demonstrates MIP formulation with Gurobi solver
â”‚   â”‚
â”‚   â”œâ”€â”€ Deterministic_Setting_Gurobi_Model_With_Variable_Driver_Reliability.py
â”‚   â”‚       â†’ Extended model accounting for driver reliability (no-show probability)
â”‚   â”‚
â”‚   â”œâ”€â”€ Generate_Random_data.py
â”‚   â”‚       â†’ Synthetic data generator for testing (driver/order locations, revenues)
â”‚   â”‚
â”‚   â”œâ”€â”€ Myopic_functions.py & Test_Myopic_collect_stats.py
â”‚   â”‚       â†’ Myopic (greedy) policy baseline for comparison
â”‚   â”‚
â”‚   â”œâ”€â”€ Multiple decision epochs/
â”‚   â”‚       â†’ Extension to multi-period setting (still deterministic demand)
â”‚   â”‚
â”‚   â””â”€â”€ Reinforcement_Learning/
â”‚       â””â”€â”€ Temporal difference learning to solve TSP.ipynb
â”‚               â†’ Q-Learning demonstration on TSP (educational, shows RL concepts)
â”‚
â”œâ”€â”€ ğŸ“ Deterministic-Matching-Policy/   [APPROACH 2: Multi-Period with Wage Guarantees]
â”‚   â”‚
â”‚   â”‚   MAIN IMPLEMENTATION of the paper's algorithm. Solves the fleet size
â”‚   â”‚   planning problem over MULTIPLE periods with STOCHASTIC demand and
â”‚   â”‚   DRIVER WAGE GUARANTEE constraints.
â”‚   â”‚
â”‚   â”œâ”€â”€ Functions.py
â”‚   â”‚       â†’ Core algorithms:
â”‚   â”‚         â€¢ boltzmann(): Softmax policy for pool size selection
â”‚   â”‚         â€¢ sample_path(): Poisson demand/supply simulation
â”‚   â”‚         â€¢ solve_opt(): Real-time LP matching with utilization tracking
â”‚   â”‚         â€¢ Driver/Demand classes: State tracking for guarantee enforcement
â”‚   â”‚         â€¢ cal_rho_a(): Priority scoring for underutilized drivers
â”‚   â”‚
â”‚   â”œâ”€â”€ Main.py
â”‚   â”‚       â†’ Training/evaluation loop:
â”‚   â”‚         â€¢ Iterates through N simulation runs
â”‚   â”‚         â€¢ Tracks: demand fulfillment rate, fraction meeting wage guarantee
â”‚   â”‚         â€¢ Outputs confidence intervals for statistical significance
â”‚   â”‚
â”‚   â”œâ”€â”€ Generate_Random_data_wage_guarantee.py
â”‚   â”‚       â†’ Instance generator with wage guarantee parameters
â”‚   â”‚
â”‚   â””â”€â”€ data/
â”‚           â†’ Pre-generated test instances (T=192 epochs = 16 hours)
â”‚
â”œâ”€â”€ ğŸ“ Stochastic-Zone-Based-Routing/   [APPROACH 3: Spatial Decomposition]
â”‚   â”‚   (Renamed from "MCDRP code" for clarity)
â”‚   â”‚
â”‚   â”‚   Advanced model that adds GEOGRAPHIC ZONES to the problem. Drivers
â”‚   â”‚   can only serve orders within their zone or adjacent zones. Useful
â”‚   â”‚   for large cities with distinct neighborhoods.
â”‚   â”‚
â”‚   â”œâ”€â”€ Model_unified_same_zone_matching_Sahil.py
â”‚   â”‚       â†’ Multi-stage stochastic program with:
â”‚   â”‚         â€¢ Zone-based matching constraints (drivers serve nearby areas)
â”‚   â”‚         â€¢ Scenario decomposition for demand uncertainty
â”‚   â”‚         â€¢ Driver repositioning between zones
â”‚   â”‚
â”‚   â””â”€â”€ run_all_Sahil.py
â”‚           â†’ Batch experiment runner for parameter sweeps
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## How the Approaches Differ

| Aspect | Deterministic Matching | Deterministic-Matching-Policy | Stochastic-Zone-Based-Routing |
|--------|----------------------|------------------------------|------------------------------|
| **Time Horizon** | Single period | Multi-period (16 hours) | Multi-period |
| **Demand Model** | Known (deterministic) | Stochastic (Poisson) | Stochastic (scenarios) |
| **Geography** | Flat (no zones) | Flat (no zones) | Zone-based network |
| **Wage Guarantee** | Not considered | âœ… Core feature | Not primary focus |
| **Algorithm** | MIP (Gurobi) | Softmax Policy + LP | Stochastic MIP |
| **Use Case** | Baseline/benchmark | **Main algorithm** | Large-scale cities |

---

## The Algorithm (Deterministic-Matching-Policy)

### High-Level Flow

```
For each planning period p = 1, 2, ..., 16:
    1. DECIDE pool size x[p] using Softmax policy
    2. SIMULATE driver arrivals (binomial from pool)
    3. For each epoch t in period p:
        a. OBSERVE new demand arrivals (Poisson)
        b. SOLVE matching LP: assign drivers to orders
           - Maximize: platform profit + utilization incentives
           - Subject to: driver capacity, demand coverage, time windows
        c. UPDATE driver states (location, utilization, earnings)
    4. TRACK metrics: demand fulfilled, drivers meeting guarantee
    5. UPDATE value function V[p, x] based on outcomes
```

### Key Innovation: Utilization-Aware Matching

The matching objective includes a **priority term** Ï_a that gives underutilized drivers higher priority:

```python
# Priority function: higher score for drivers below 80% utilization
def cal_rho_a(bar_ha):  # bar_ha = current utilization rate
    if bar_ha < 0.8:    # Below wage guarantee threshold
        return -1.25 * bar_ha + 1  # Higher priority
    return 0  # Already meeting guarantee
```

This ensures the platform **preferentially assigns orders to drivers who need more work** to meet their wage guarantee.

### Softmax Policy for Pool Sizing

Instead of using a fixed pool size, the algorithm **learns optimal pool sizes** through a value function V[period, pool_size]:

```python
# Boltzmann/Softmax selection with temperature annealing
P(pool_size = k) âˆ exp(-Î¶ Â· V[period, k])
```

- Early training: High temperature â†’ exploration (try different pool sizes)
- Later training: Low temperature â†’ exploitation (use best-performing sizes)

---

## Performance Metrics

The algorithm optimizes for two competing objectives:

1. **Demand Fulfillment Rate** = (Orders Fulfilled) / (Total Orders)
2. **Wage Guarantee Rate** = (Drivers Meeting Threshold) / (Total Drivers)

Results show the trade-off frontierâ€”as we increase pool size, fulfillment rises but guarantee rate falls.

---

## Installation & Usage

### Prerequisites
- Python 3.8+
- Gurobi Optimizer (free academic license at [gurobi.com](https://www.gurobi.com/academia/academic-program-and-licenses/))

### Setup

```bash
git clone https://github.com/sahilpbhatt1/Fleet-Size-Planning-in-Crowdsourced-Delivery.git
cd Fleet-Size-Planning-in-Crowdsourced-Delivery
pip install -r requirements.txt
```

### Run the Main Algorithm

```bash
cd Deterministic-Matching-Policy
python Main.py
```

### Run Driver-Order Matching Demo

```bash
cd Deterministic_Matching
python Deterministic_Setting_Gurobi_Model_With_Fixed_Profit.py
```

---

## Technical Components

| Category | Details |
|----------|---------|
| **Mathematical Optimization** | Linear/Mixed-Integer Programming, Gurobi/CPLEX, Constraint formulation |
| **Stochastic Modeling** | Poisson processes, Scenario-based optimization, Monte Carlo simulation |
| **Machine Learning** | Reinforcement Learning (Q-Learning), Value function approximation, Softmax policies |
| **Algorithm Design** | Bipartite matching, Priority queues, Temporal decomposition |
| **Software Engineering** | Modular Python design, Statistical analysis, Experiment automation |

---

## Research Paper

This code implements the algorithms from:

**"Fleet Size Planning in Crowdsourced Delivery: Balancing Service Level and Driver Utilization"**

The paper addresses a novel research question at the intersection of:
- Operations Research (workforce scheduling, vehicle routing)
- Gig Economy (crowdsourced platforms, wage guarantees)
- Sequential Decision Making (multi-period optimization under uncertainty)

---

## Author

**Sahil Bhatt**  
Research Interests: Operations Research, Optimization, Machine Learning for Decision Making

---

## License

MIT License - See [LICENSE](LICENSE) for details
